from typing import Any

from agentica_internal.internal_errors.bugs import ThisIsABug
from agentica_internal.internal_errors.generation import InferenceError

from com.constraints import *
from com.context import Context
from com.deltas import *
from com.roles import *

__all__ = [
    'convert_from_constraints',
    'make_end',
    'convert_to_role',
    'convert_to_delta',
]


async def convert_from_constraints(
    ctx: Context, constraints: list[Constraint], validate: bool = True
) -> dict[str, Any]:
    """
    Makes a dictionary of kwargs according to a list of generation constraints for the OpenAI Chat Completions API.
    Includes:
    - stop tokens
    - response format
    - max tokens
    - tools
    - tool choice

    Args:
        ctx: The context.
        constraints: The constraints.

    Returns:
        The kwargs.
    """
    kwargs = {}

    # if ctx.gen.type != 'json' and ctx.gen.guided:
    #     raise ValueError(f"Support for code constraints is not implemented yet")

    stop_tokens = [c.token for c in constraints if isinstance(c, StopTokenConstraint)]
    max_tokens = [c.max_tokens for c in constraints if isinstance(c, MaxTokensConstraint)]

    if stop_tokens:
        kwargs['stop'] = stop_tokens

    if max_tokens:
        kwargs['max_completion_tokens'] = max_tokens[0]

    return kwargs


def make_end(
    choice: dict[str, Any], constraints: list[Constraint], *, streaming: bool = False
) -> EndGen:
    """
    Makes an End object from a Choice generated by the OpenAI Chat Completions API and a list of constraints.

    Args:
        choice: The choice.
        constraints: The constraints.
    """
    key = 'delta' if streaming else 'message'
    if choice[key].get('tool_calls', None):
        # JSON mode is disabled.
        raise ThisIsABug("Tool calls should not be happening (got 'tool_calls' in message)")
        # callable_constraints = [c for c in constraints if isinstance(c, CallableConstraint)]
        # return make_callable_end(choice['message']['tool_calls'], callable_constraints)

    # OpenRouter normalizes each modelâ€™s `finish_reason` to one of the following values:
    # tool_calls, stop, length, content_filter, error.

    finish_reason = choice.get('finish_reason', None)
    if not finish_reason:
        # presume normal finish
        return EndGenEOS()

    match finish_reason:
        case 'tool_calls':
            raise ThisIsABug("Tool calls should not be happening (got 'tool_calls' finish reason)")
            # callable_constraints = [c for c in constraints if isinstance(c, CallableConstraint)]
            # return make_callable_end(choice['message']['tool_calls'], callable_constraints)
        case 'length':
            return EndGenMaxTokens(
                constraint=next(c for c in constraints if isinstance(c, MaxTokensConstraint)),
            )
        case 'stop':
            return EndGenStopToken(
                constraint=StopTokenConstraint(token=choice.get('stop_text', '')),
            )
        case 'content_filter' | 'filter_content':
            return EndGenStopToken(
                constraint=None,
                filtered=True,
            )
        case 'error':
            raise InferenceError(
                None,
                None,
                message=f'Finish reason: error: {choice.get("error", {}).get("message", "Unknown error")}',
            )
        case _:
            if streaming:
                return EndGenEOS()
            else:
                raise ValueError(f"Invalid finish reason: {choice['finish_reason']}")


def convert_to_role(role: str, name: str | None = None) -> GenRole:
    """
    Converts a string role to a Role object.

    Args:
        role: The string role to convert.
        name: The name of the user if the role is 'user'.

    Returns:
        The Role object.
    """
    assert role == 'user' or name is None, "Only user messages can have a name"
    match role:
        case 'user':
            return UserRole(username=name)
        case 'assistant':
            return AgentRole()
        case 'system':
            return SystemRole()
        case _:
            raise ValueError(f"Invalid role: {role}")


def convert_to_delta(
    choice: dict[str, Any],
    constraints: list[Constraint],
    *,
    streaming: bool = False,
) -> GeneratedDelta:
    """
    Makes a GeneratedDelta object from a Choice generated by the OpenAI Chat Completions API and a list of constraints.

    Args:
        choice: The choice.
        constraints: The constraints.
    """
    if streaming:
        msg = choice['delta']
    else:
        msg = choice['message']
    return GeneratedDelta(
        id=msg.get('id', None),
        name=convert_to_role(msg.get('role', None), msg.get('name', None)),
        content=msg.get('content', None),
        end=make_end(choice, constraints, streaming=streaming),
        constraints=constraints,
        reasoning_content=msg.get('reasoning_content', None),
        annotations=msg.get('annotations', None),
        audio=msg.get('audio', None),
        refusal=msg.get('refusal', None),
    )
